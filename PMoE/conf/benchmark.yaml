# Environment Config
env:
  host: 'localhost' # IP of the host server (default: localhost)'
  port: 2000
  trafficManagerSeed: 0 # Seed used by the TrafficManager (default: 0)
  timeout: 60.0 # Set the CARLA client timeout value in seconds
  repetitions: 1 # Number of repetitions per route.
  track: 'SENSORS' # Participation track: SENSORS, MAP
  checkpoint: './simulation_results.json' # Path to checkpoint used for saving statistics and resuming
#  suite: 'town1' # choices=ALL_SUITES
#  big_cam: True
  seed: 2021
#  autopilot: False
#  show: False
#  max_run: 1
#  show_preview: False # whether or not we want to show a preview
  resume: False # Resume execution from last checkpoint?
  img_width: 800
  img_height: 600
  fov: '100'
  n_vehicles: 100  # The range for the random numbers that are going to be generated
  n_pedestrians: 250
  n_commands: 6


# Logger parameters
logger:
   project: "PMoE" # project name or workspace
   tags: "benchmark NoCrash"
   resume: False # (boolean) whether to resume training or not
   experiment_key: None # can be retrieved from logger dashboard, available if only resuming
  log_dir: "PMoE/logs" # where to store log data

# model parameters
model:
  # type: 'moe' # network type. Valid values are: punet, punet_inter, moe, moe_alt, moe_shared, pmoe, pmoe+pretrained, rl_agent
  actor:
    n_commands: 6
    device: "cpu" # device name, values: "cpu" or "cuda:x" where 'x' is gpu index
    model_dir: "PMoE/checkpoint/MoE-best.pth" # pretrained model directory, it cannot be None
    exclude_freeze: ['something',] # a list of layers to stay unfrozen
    # lr: 0.00001 # learning rate
    n_experts: 3 # number of experts to be used
    # exclude_freeze: [ 'model_weights', 'alpha' ] # a list of layers to stay unfrozen
    type: 'moe' # network type. Valid values are: punet, punet_inter, moe, moe_alt, moe_shared, pmoe, pmoe+pretrained
    # model_dir: "../checkpoint/moe-e4-best.pth" # pretrained model directory, it cannot be None
    verbose: True # show some statistics about model parameters or notn_experts: 3 # number of experts to be used
    action_head: # speed encoder network, just an MLP
      dims: [ 1536, 512, 512 ] # MLP dimensions. First dim should always be 1536
      act: 'elu' # type of activation function. Valid values: [relu, tanh, sigmoid, elu]
      l_act: True # use activation function on the last layer or just return scores/logits?
      bn: False # use batchnorm?
      dropout: 0.3
    speed_encoder: # speed encoder network, just an MLP
      dims: [ 1, 512, 512 ] # MLP dimensions. First dim should always be 1
      act: 'relu' # type of activation function. Valid values: [relu, tanh, sigmoid, elu]
      l_act: False # use activation function on the last layer or just return scores/logits?
      bn: False # use batchnorm?
      dropout: 0.3
    command_encoder: # command encoder network, just an MLP
      dims: [ 6, 512, 512 ] # MLP dimensions. First dim should always be 4
      act: 'relu' # type of activation function. Valid values: [relu, tanh, sigmoid, elu]
      l_act: False # use activation function on the last layer or just return scores/logits?
      bn: False # use batchnorm?
      dropout: 0.3
    speed_prediction: # speed prediction head, just an MLP
      dims: [ 1536, 512, 512, 1 ] # MLP dimensions. First dim should always be 1536
      act: 'relu' # type of activation function. Valid values: [relu, tanh, sigmoid, elu]
      l_act: False # use activation function on the last layer or just return scores/logits?
      bn: False # use batchnorm?
      dropout: 0.3
    backbone: # visual feature extractor
      type: 'rgb' # valid values: rgb, segmentation
      n_frames: 4 # number of input frames
      rgb: # configs for resnet and mobilenet models
        arch: 'resnet18' # valid values: resnet18/34/50, mobilenet_v2/3_small/large
        pretrained: False
        gamma: 2 # ECA gamma parameter
        b: 1 # ECA b parameter
      segmentation:
        gamma: 2
        b: 1
        inter_repr: True # always true for this stage
        model_dir: "PMoE/checkpoint/unet-best.pth"
    punet:
      past_frames: 4 # please note that data is captured at 2hz
      future_frames: 4
      in_features: 3
      num_classes: 23 # number of segmentation classes, for carla 0.9.6+ it is 23
      gamma: 2 # gamma parameter of eca module
      b: 1 # b parameter of eca module
      #inter_repr: False # whether PU-Net returns intermediate representation or not (not intended for training)
      unet_inter_repr: False # whether U-Net returns intermediate representation or not (set to True if future_frames is 0)
      model_name: "unet-swa"
      model_path: "PMoE/checkpoint/unet-best.pth"
    pmoe:
      moe_dir: "PMoE/checkpoint/MoE-e50.pth" # MoE pretrained model directory, it cannot be None
      punet_dir: "" # PU-Net pretrained model with actions directory
  critic:
    lr: 0.001
    backbone: # visual feature extractor
      type: 'rgb' # valid values: rgb, segmentation
      n_frames: 4 # number of input frames
      rgb: # configs for resnet and mobilenet models
        arch: 'resnet18' # valid values: resnet18/34/50, mobilenet_v2/3_small/large
        pretrained: False
        gamma: 2 # ECA gamma parameter
        b: 1 # ECA b parameter
      segmentation:
        gamma: 2
        b: 1
        inter_repr: True # always true for this stage
        model_dir: "PMoE/checkpoint/unet-best.pth"

    speed_encoder: # speed encoder network, just an MLP
      dims: [ 1, 128, 128 ] # MLP dimensions. First dim should always be 1
      act: 'relu' # type of activation function. Valid values: [relu, tanh, sigmoid, elu]
      l_act: False # use activation function on the last layer or just return scores/logits?
      bn: False # use batchnorm?
      dropout: 0.3

    command_encoder: # command encoder network, just an MLP
      dims: [ 4, 128, 128 ] # MLP dimensions. First dim should always be 4
      act: 'relu' # type of activation function. Valid values: [relu, tanh, sigmoid, elu]
      l_act: False # use activation function on the last layer or just return scores/logits?
      bn: False # use batchnorm?
      dropout: 0.3

    action_encoder: # action encoder network, just an MLP
      dims: [ 2, 128, 128 ] # MLP dimensions. First dim should always be 4
      act: 'relu' # type of activation function. Valid values: [relu, tanh, sigmoid, elu]
      l_act: False # use activation function on the last layer or just return scores/logits?
      bn: False # use batchnorm?
      dropout: 0.3

    value_prediction: # value prediction head, just an MLP
      dims: [ 896, 512, 256, 256, 1 ] # MLP dimensions. First dim is the sum of [backbone, speed_encoder, command_encoder, action_encoder] outputs dim
      act: 'relu' # type of activation function. Valid values: [relu, tanh, sigmoid, elu]
      l_act: False # use activation function on the last layer or just return scores/logits?
      bn: False # use batchnorm?
      dropout: 0.3
